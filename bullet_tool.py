import numpy as np
from scipy.spatial.transform import Rotation as R
import pybullet as p
import open3d as o3d
import cv2
import time

'''
有些在pybullet中用处比较大的自写函数，作为辅佐工具
陆续完善
'''
###########
'''
坐标可视化
'''
class DebugAxes(object):
    """
    可视化基于base的坐标系, 红色x轴, 绿色y轴, 蓝色z轴
    常用于检查当前关节pose或者测量关键点的距离
    用法:
    goalPosition1 = DebugAxes()
    goalPosition1.update([0,0.19,0.15
                         ],[0,0,0,1])
    """
    def __init__(self):
        self.uids = [-1, -1, -1]

    def update(self, pos, orn):
        """
        Arguments:
        - pos: len=3, position in world frame
        - orn: len=4, quaternion (x, y, z, w), world frame
        """
        pos = np.asarray(pos).reshape(3)

        rot3x3 = R.from_quat(orn).as_matrix()
        axis_x, axis_y, axis_z = rot3x3.T
        self.uids[0] = p.addUserDebugLine(pos, pos + axis_x * 0.05, [1, 0, 0], replaceItemUniqueId=self.uids[0])
        self.uids[1] = p.addUserDebugLine(pos, pos + axis_y * 0.05, [0, 1, 0], replaceItemUniqueId=self.uids[1])
        self.uids[2] = p.addUserDebugLine(pos, pos + axis_z * 0.05, [0, 0, 1], replaceItemUniqueId=self.uids[2])


'''
相机参数、rgbd、点云设置
'''

class Camera(object):
    """Virtual RGB-D camera based on the PyBullet camera interface.

    Attributes:
        intrinsic: The camera intrinsic parameters.
    """

    def __init__(self, intrinsic, near=0.01, far=4):
        self.intrinsic = intrinsic
        self.near = near
        self.far = far
        self.proj_matrix = _build_projection_matrix(intrinsic, near, far)
        self.gl_proj_matrix = self.proj_matrix.flatten(order="F")

    def render(self, extrinsic):
        """Render synthetic RGB and depth images.

        Args:
            extrinsic: Extrinsic parameters, T_cam_ref.
        """
        # Construct OpenGL compatible view and projection matrices.
        gl_view_matrix = extrinsic.copy() if extrinsic is not None else np.eye(4)
        gl_view_matrix[2, :] *= -1  # flip the Z axis
        gl_view_matrix = gl_view_matrix.flatten(order="F")

        result = p.getCameraImage(
            width=self.intrinsic.width,
            height=self.intrinsic.height,
            viewMatrix=gl_view_matrix,
            projectionMatrix=self.gl_proj_matrix,
            renderer=p.ER_BULLET_HARDWARE_OPENGL,
        )

        rgb, z_buffer = np.ascontiguousarray(result[2][:, :, :3]), result[3]
        depth = (
                1.0 * self.far * self.near / (self.far - (self.far - self.near) * z_buffer)
        )

        return Frame(rgb, depth, self.intrinsic, extrinsic)


class Frame(object):
    def __init__(self, rgb, depth, intrinsic, extrinsic=None):
        self.rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(
            color=o3d.geometry.Image(rgb),
            depth=o3d.geometry.Image(depth),
            depth_scale=1.0,
            depth_trunc=2.0,
            convert_rgb_to_intensity=False
        )

        self.intrinsic = o3d.camera.PinholeCameraIntrinsic(
            width=intrinsic.width,
            height=intrinsic.height,
            fx=intrinsic.fx,
            fy=intrinsic.fy,
            cx=intrinsic.cx,
            cy=intrinsic.cy,
        )

        self.extrinsic = extrinsic if extrinsic is not None \
            else np.eye(4)

    def color_image(self):
        return np.asarray(self.rgbd.color)

    def depth_image(self):
        return np.asarray(self.rgbd.depth)

    def point_cloud(self):
        pc = o3d.geometry.PointCloud.create_from_rgbd_image(
            image=self.rgbd,
            intrinsic=self.intrinsic,
            extrinsic=self.extrinsic
        )

        return pc


def _build_projection_matrix(intrinsic, near, far):
    perspective = np.array(
        [
            [intrinsic.fx, 0.0, -intrinsic.cx, 0.0],
            [0.0, intrinsic.fy, -intrinsic.cy, 0.0],
            [0.0, 0.0, near + far, near * far],
            [0.0, 0.0, -1.0, 0.0],
        ]
    )
    ortho = _gl_ortho(0.0, intrinsic.width, intrinsic.height, 0.0, near, far)
    return np.matmul(ortho, perspective)


def _gl_ortho(left, right, bottom, top, near, far):
    ortho = np.diag(
        [2.0 / (right - left), 2.0 / (top - bottom), -2.0 / (far - near), 1.0]
    )
    ortho[0, 3] = -(right + left) / (right - left)
    ortho[1, 3] = -(top + bottom) / (top - bottom)
    ortho[2, 3] = -(far + near) / (far - near)
    return ortho


class CameraIntrinsic(object):
    """Intrinsic parameters of a pinhole camera model.

    Attributes:
        width (int): The width in pixels of the camera.
        height(int): The height in pixels of the camera.
        K: The intrinsic camera matrix.
    """

    def __init__(self, width, height, fx, fy, cx, cy):
        self.width = width
        self.height = height
        self.K = np.array(
            [[fx, 0.0, cx],
             [0.0, fy, cy],
             [0.0, 0.0, 1.0]]
        )

    @property
    def fx(self):
        return self.K[0, 0]

    @property
    def fy(self):
        return self.K[1, 1]

    @property
    def cx(self):
        return self.K[0, 2]

    @property
    def cy(self):
        return self.K[1, 2]

    def to_dict(self):
        """Serialize intrinsic parameters to a dict object."""
        data = {
            "width": self.width,
            "height": self.height,
            "K": self.K.flatten().tolist(),
        }
        return data

    @classmethod
    def from_dict(cls, data):
        """Deserialize intrinisic parameters from a dict object."""
        intrinsic = cls(
            width=data["width"],
            height=data["height"],
            fx=data["K"][0],
            fy=data["K"][4],
            cx=data["K"][2],
            cy=data["K"][5],
        )
        return intrinsic


'''
绑定相机位置并获取更新图像
'''
def update_camera_image_to_end(end_state,camera):
    cv2.namedWindow("image")
    end_pos = end_state[0]
    end_orn = end_state[1]
    wcT = _bind_camera_to_end(end_pos, end_orn)
    cwT = np.linalg.inv(wcT)

    frame = camera.render(cwT)
    assert isinstance(frame, Frame)

    rgb = frame.color_image()  # 这里以显示rgb图像为例, frame还包含了深度图, 也可以转化为点云
    bgr = np.ascontiguousarray(rgb[:, :, ::-1])  # flip the rgb channel

    cv2.namedWindow("image")
    cv2.imshow("image", bgr)
    key = cv2.waitKey(10)
    # time.sleep(10)

    return bgr


def _bind_camera_to_end(end_pos, end_orn_or):
    """设置相机坐标系与末端坐标系的相对位置

    Arguments:
    - end_pos: len=3, end effector position
    - end_orn: len=4, end effector orientation, quaternion (x, y, z, w)

    Returns:
    - wcT: shape=(4, 4), transform matrix, represents camera pose in world frame
    """
    relative_offset = [-0.08, 0, 0.1]  # 相机原点相对于末端执行器局部坐标系的偏移量
    end_orn = R.from_quat(end_orn_or).as_matrix()
    end_x_axis, end_y_axis, end_z_axis = end_orn.T


    wcT = np.eye(4)  # w: world, c: camera, ^w_c T
    wcT[:3, 0] = -end_y_axis  # camera x axis
    wcT[:3, 1] = -end_z_axis  # camera y axis
    wcT[:3, 2] = end_x_axis  # camera z axis
    wcT[:3, 3] = end_orn.dot(relative_offset) + end_pos  # eye position
    fg = R.from_euler('XYZ', [-0.35, 0, 0]).as_matrix()

    wcT[:3, :3] = np.matmul(wcT[:3, :3], fg)

    camera_link = DebugAxes()
    camera_link.update(wcT[:3,3],R.from_matrix(wcT[:3, :3]).as_quat())


    return wcT


def update_camera_image_to_base(end_state,relative_offset,camera):

    end_pos = end_state[0]
    end_orn = end_state[1]
    wcT = _bind_camera_to_base(end_pos, end_orn,relative_offset)
    cwT = np.linalg.inv(wcT)

    frame = camera.render(cwT)
    assert isinstance(frame, Frame)

    rgb = frame.color_image()  # 这里以显示rgb图像为例, frame还包含了深度图, 也可以转化为点云
    bgr = np.ascontiguousarray(rgb[:, :, ::-1])  # flip the rgb channel



    rgbd = frame.depth_image()

    import matplotlib
    matplotlib.use('TkAgg')  # 大小写无所谓 tkaGg ,TkAgg 都行
    import matplotlib.pyplot as plt

    plt.figure(num=1)
    plt.imshow(rgb)
    plt.show()

    plt.figure(num=2)
    plt.imshow(rgbd)
    plt.show()

    # cv2.namedWindow("image")
    # cv2.imshow("image", bgr)
    # key = cv2.waitKey(10)
    # time.sleep(10)
    p=1

    return bgr


def _bind_camera_to_base(end_pos, end_orn_or,relative_offset):
    """设置相机坐标系与末端坐标系的相对位置

    Arguments:
    - end_pos: len=3, end effector position
    - end_orn: len=4, end effector orientation, quaternion (x, y, z, w)

    Returns:
    - wcT: shape=(4, 4), transform matrix, represents camera pose in world frame
    """
    camera_link = DebugAxes()

    end_orn = R.from_quat(end_orn_or).as_matrix()
    end_x_axis, end_y_axis, end_z_axis = end_orn.T

    wcT = np.eye(4)  # w: world, c: camera, ^w_c T
    wcT[:3, 0] = -end_y_axis  # camera x axis
    wcT[:3, 1] = -end_z_axis  # camera y axis
    wcT[:3, 2] = end_x_axis  # camera z axis
    wcT[:3, 3] = end_orn.dot(relative_offset) + end_pos  # eye position
    fg = R.from_euler('XYZ', [-np.pi/2, 0, 0]).as_matrix()

    wcT[:3, :3] = np.matmul(wcT[:3, :3], fg)


    camera_link.update(wcT[:3,3],R.from_matrix(wcT[:3, :3]).as_quat())

    p=0



    return wcT